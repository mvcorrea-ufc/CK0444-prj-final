name: 'Data Pipeline'

on:
  push:
    branches:
      - main
    paths:
      - 'sdp-data/**'
      - '.github/workflows/data-pipeline.yml'
  pull_request:
    paths:
      - 'sdp-data/**'
      - '.github/workflows/data-pipeline.yml'
  workflow_dispatch: # Allows manual triggering

jobs:
  build-data-pipeline:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install uv
        run: |
          curl -LsSf https://astral.sh/uv/install.sh | sh
          echo "$HOME/.cargo/bin" >> $GITHUB_PATH
        shell: bash

      - name: Create Virtual Environment
        run: uv venv

      - name: Install dependencies
        run: uv pip install -r requirements.txt

      - name: Run Data Pipeline
        run: uv run python sdp-data/pipeline.py

      - name: Upload Dataset Artifact
        uses: actions/upload-artifact@v4
        with:
          name: sdp-dataset
          path: sdp-data/dados_completos.csv
          if-no-files-found: error # Fails the workflow if the file isn't found
